# ğŸ“Š Compte rendu Machine Learning & Analyse Statistique

**Projet :** Analyse de lâ€™impact de lâ€™IA sur les emplois Ã  lâ€™horizon 2030
**Dataset :** *AI_Impact_on_Jobs_2030.csv*
**Auteur :** Douaa El Khayari
**Contexte acadÃ©mique :** Analyse de donnÃ©es & Machine Learning

---

## 1. Introduction

Ce projet vise Ã  analyser lâ€™impact potentiel de lâ€™intelligence artificielle sur les emplois Ã  lâ€™horizon 2030 Ã  partir dâ€™un jeu de donnÃ©es structurÃ©. Lâ€™objectif est double :

* RÃ©aliser une **analyse statistique descriptive** afin de comprendre la structure et les caractÃ©ristiques des donnÃ©es.
* Mettre en place des **modÃ¨les de rÃ©gression / classification** pour prÃ©dire et expliquer certains niveaux de compÃ©tences liÃ©s aux mÃ©tiers.

---

## 2. PrÃ©sentation du dataset

Le dataset contient **3000 observations** et **18 variables**, composÃ©es de :

* Variables numÃ©riques : indicateurs de compÃ©tences, scores, niveaux dâ€™exposition Ã  lâ€™IA.
* Variables catÃ©gorielles : secteurs, types de mÃ©tiers, classifications professionnelles.

La variable principale Ã©tudiÃ©e dans la modÃ©lisation est **Skill_10**, transformÃ©e en variable binaire afin de permettre une approche en classification.

---

## 3. Analyse statistique descriptive

### 3.1 Tableau des statistiques descriptives

Un tableau de statistiques descriptives a Ã©tÃ© gÃ©nÃ©rÃ© pour lâ€™ensemble des variables numÃ©riques du dataset. Ce tableau prÃ©sente :

* La moyenne
* La mÃ©diane
* Lâ€™Ã©cart-type
* Les valeurs minimale et maximale

ğŸ“Š **Tableau 1 â€“ Statistiques descriptives des variables numÃ©riques**
(Ce tableau est issu de la fonction `describe()` de *pandas* et est affichÃ© dans le notebook.)

Ces indicateurs permettent dâ€™Ã©valuer la dispersion des donnÃ©es, leur homogÃ©nÃ©itÃ© et dâ€™identifier dâ€™Ã©ventuelles anomalies.

---

### 3.2 Graphiques de distribution

Des graphiques de distribution (histogrammes) ont Ã©tÃ© gÃ©nÃ©rÃ©s pour les principales variables numÃ©riques afin dâ€™analyser leur forme (symÃ©trie, concentration, dispersion).

ğŸ“ˆ **Figure 1 â€“ Histogrammes des variables de compÃ©tences**

Lâ€™analyse graphique montre que la majoritÃ© des variables prÃ©sentent des distributions relativement Ã©quilibrÃ©es, ce qui est favorable Ã  lâ€™application de modÃ¨les statistiques et de Machine Learning.

---

### 3.2 Analyse de la distribution

Les distributions des variables numÃ©riques montrent une relative homogÃ©nÃ©itÃ© des scores de compÃ©tences, avec quelques variations selon les dimensions analysÃ©es. Cette Ã©tape est essentielle pour justifier lâ€™utilisation de modÃ¨les statistiques et de Machine Learning.

---

## 4. Matrice de corrÃ©lation

Une matrice de corrÃ©lation a Ã©tÃ© construite Ã  partir des variables numÃ©riques afin dâ€™identifier les relations linÃ©aires entre les diffÃ©rentes compÃ©tences.

ğŸ“Š **Tableau 2 â€“ Matrice de corrÃ©lation (coefficients de Pearson)**

En complÃ©ment, une visualisation graphique sous forme de heatmap a Ã©tÃ© rÃ©alisÃ©e.

ğŸ“‰ **Figure 2 â€“ Heatmap de la matrice de corrÃ©lation**

### InterprÃ©tation :

* Certaines variables de compÃ©tences prÃ©sentent une corrÃ©lation positive modÃ©rÃ©e Ã  forte, indiquant des Ã©volutions conjointes.
* Aucune corrÃ©lation extrÃªme nâ€™a Ã©tÃ© observÃ©e, ce qui limite le risque de multicolinÃ©aritÃ© dans les modÃ¨les de rÃ©gression.

La matrice de corrÃ©lation constitue un outil fondamental pour orienter la sÃ©lection des variables explicatives.

---

## 5. ModÃ©lisation et rÃ©gressions

### 5.1 PrÃ©traitement des donnÃ©es

Avant la modÃ©lisation, plusieurs Ã©tapes de prÃ©traitement ont Ã©tÃ© appliquÃ©es :

* Imputation des valeurs manquantes (mÃ©diane / valeur la plus frÃ©quente)
* Standardisation des variables numÃ©riques
* Encodage des variables catÃ©gorielles (One-Hot Encoding)
* SÃ©paration des donnÃ©es en **jeu dâ€™entraÃ®nement (80%)** et **jeu de test (20%)**

---

### 5.2 Algorithmes utilisÃ©s

Deux algorithmes de Machine Learning ont Ã©tÃ© implÃ©mentÃ©s :

* **Logistic Regression** : modÃ¨le linÃ©aire utilisÃ© comme rÃ©fÃ©rence pour la classification binaire.
* **Random Forest Classifier** : algorithme dâ€™ensemble basÃ© sur des arbres de dÃ©cision, capable de capturer des relations non linÃ©aires.

---

### 5.3 RÃ©sultats des modÃ¨les

Les performances des modÃ¨les ont Ã©tÃ© comparÃ©es Ã  lâ€™aide dâ€™un tableau rÃ©capitulatif.

ğŸ“Š **Tableau 3 â€“ Comparaison des performances des modÃ¨les**

| ModÃ¨le              | Accuracy    |
| ------------------- | ----------- |
| Logistic Regression | Ã‰levÃ©e      |
| Random Forest       | TrÃ¨s Ã©levÃ©e |

Ces rÃ©sultats montrent la supÃ©rioritÃ© du modÃ¨le Random Forest sur ce jeu de donnÃ©es.

---

## 6. Matrice de confusion

La matrice de confusion du meilleur modÃ¨le (Random Forest) a Ã©tÃ© reprÃ©sentÃ©e graphiquement afin dâ€™Ã©valuer la qualitÃ© des prÃ©dictions.

ğŸ“‰ **Figure 3 â€“ Matrice de confusion (Random Forest)**

Cette visualisation met en Ã©vidence :

* Un nombre trÃ¨s Ã©levÃ© de prÃ©dictions correctes
* Un taux dâ€™erreur extrÃªmement faible

Elle confirme ainsi la robustesse et la fiabilitÃ© du modÃ¨le sÃ©lectionnÃ©.

---

## 7. Conclusion

Ce projet a permis de :

* Comprendre la structure et les relations internes du dataset grÃ¢ce Ã  lâ€™analyse statistique descriptive
* Identifier les liens entre les compÃ©tences via la matrice de corrÃ©lation
* Mettre en Å“uvre des modÃ¨les de Machine Learning performants

Le **Random Forest Classifier** sâ€™est rÃ©vÃ©lÃ© Ãªtre le modÃ¨le le plus adaptÃ© pour ce problÃ¨me, offrant des rÃ©sultats trÃ¨s satisfaisants.

---

## 8. Perspectives

Pour aller plus loin, plusieurs pistes peuvent Ãªtre envisagÃ©es :

* Utiliser des modÃ¨les de rÃ©gression avancÃ©s (XGBoost, Gradient Boosting)
* Effectuer une sÃ©lection automatique des variables
* Ã‰tudier lâ€™importance des variables pour interprÃ©ter lâ€™impact de lâ€™IA sur les compÃ©tences

---

ğŸ“Œ *Ce dÃ©pÃ´t GitHub contient le dataset, les notebooks de traitement, les modÃ¨les entraÃ®nÃ©s ainsi que ce compte rendu analytique.*
